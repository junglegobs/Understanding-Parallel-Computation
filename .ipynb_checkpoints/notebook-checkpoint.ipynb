{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding Parallel Computation with Julia \n",
    "---\n",
    "\n",
    "This notebook covers the following:\n",
    "* Untangling a jungle of jargon\n",
    "* Simple parallelism with Julia\n",
    "* Understanding layers of parallelism with Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[2K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\u001b[?25l\u001b[2K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/SpineRegistry`\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/Spine-project/SpineJuliaRegistry.git`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
      " \u001b[90m [9961bab8] \u001b[39m\u001b[92m+ Cbc v0.8.0\u001b[39m\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Cbc\")\n",
    "Pkg.add(\"JuMP\")\n",
    "using Distributed, Cbc, JuMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "There's 3 ways to speed up any process, for example making toast and marmite. You could:\n",
    "\n",
    "* Literally make the process faster by becoming faster at cutting, toasting and buttering bread.\n",
    "* Pipelining - while one bread is being toasted, you're cutting another slice of bread or buttering an already made one.\n",
    "* Parallelising - cut all pieces of bread simultaneously e.g. with that machine at the supermarket, toast them simultaneously assuming you have a large enough toaster, and butter them simultaneously by growing additional limbs (or getting help from a friend).\n",
    "\n",
    "This last one is what this notebook is all about, as you might have guessed. Your computer is able to carry out multiple tasks at the same time because it has multiple \"cores\" - it is executing them in parallel. There are many ways of doing this however, not just with multiple cores, and so this notebook tries to disentangle the confusing writing on the subject online. Keep in mind that:\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    This was written for people familiar with mathematical optimisation.\n",
    "    <br>\n",
    "    I don't care for pedantry or exactness.\n",
    "</div>\n",
    "\n",
    "## A note on asynchronous programming\n",
    "\n",
    "Before we continue however keep one thing in mind. One way your computer seems to be so fast is because it is actually doing a lot of things at once - it's reading your keyboard input, displaying it on your screen, adjusting your fan, collecting a bunch of data you're producing and sending it to God knows where. This is called [asynchronous programming](https://docs.julialang.org/en/v1/manual/asynchronous-programming/), and it can sometimes feel like parallelism, but it isn't:\n",
    "* Parallelism is performing several tasks at the same time with the same **amount** of computational resources assigned to each task. \n",
    "    * As long as the amount of resources increases with the number of tasks, the time it takes to perform all tasks will not increase (e.g. 1 core for 1 task will take more or less the same amount of time as 4 cores for 4 tasks).\n",
    "* Asynchronous programming is performing several tasks at the same time with **the same computational resources**.\n",
    "    * Performing 1 task should therefore take a quarter of the time as performing 4 tasks.\n",
    "    \n",
    "Ok, let's get cracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untangling a jungle of jargon\n",
    "\n",
    "### On a single computer\n",
    "\n",
    "People use words, and sometimes these words confusing. Let's try to clear this up a bit:\n",
    "\n",
    "* Your computer has at least one central processing unit or **CPU**. This bad boy \"does math\" so you don't have to.\n",
    "* Sometimes a CPU is called a **processor** (not to be confused with a **process**, more on that later.\n",
    "* You can (and probably do) have multiple CPUs or processors in your laptop - at this point we talk of a **multi-core processor**.\n",
    "    * Why? Because it would be too simple to stick to one name. I assume there is also some pedantry involved.\n",
    "* Having multiple **core**s means you can execute tasks in parallel, e.g. one on each core.\n",
    "* It doesn't stop there - each of your cores can have multiple **threads**. You can similarly parallelise tasks on each thread, e.g. one task on each thread.\n",
    "* Intel has some ish called [**hyper-threading**](https://en.wikipedia.org/wiki/Hyper-threading), which makes some people talk about **logical cores**.\n",
    "    * Logical cores = cores * threads per core, e.g. 4 cores * 2 threads per core = 8 logical cores.\n",
    "    * At this point I don't care though.\n",
    "\n",
    "It's actually not that difficult:\n",
    "\n",
    "Level 1 | Level 2\n",
    "--- | ---\n",
    "Cores, CPUs, processors | Threads\n",
    "\n",
    "\n",
    "At this point a rule of thumb:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Rule of thumb</b> <br> Don't worry about threads.</div>\n",
    "\n",
    "If you're desiging your own parallel simulation (as we'll do below), forget about multi-threading. It can go wrong if you don't know what your doing and it won't scale to a super computer, as I'll explain below. But first, some stuff about memory.\n",
    "\n",
    "### Memory\n",
    "\n",
    "The above mentioned cores, CPUs, processors and threads differ mainly in how and where they store data i.e. their **memory**. You don't need to worry about this honestly, but here's a photo anyway:\n",
    "\n",
    "\n",
    "The main thing to point out is that cores share memory. You don't need to do anything too complicated to transfer data between cores, it's there in your **RAM** which every core has access to.\n",
    "\n",
    "This is different on a super computer (see below) where cores do not necessarily have access to the same RAM. Transferring data at that point is less straightforward - you might have to send data over ssh for example. This should be fairly easy with Julia if you have access to a cluster, [but it may not be in practice](example).\n",
    "\n",
    "### On a super computer\n",
    "\n",
    "Some synonyms for a super computer are **high performance computing** and **cluster**. This is just a bunch of computers stuck together, with each computer sometimes called a **node** in the cluster.\n",
    "\n",
    "Most nodes on a supercomputer will have quite a lot of cores (e.g. 20 or more), so you can perform **shared memory** parallelism here. What this means it that all your cores have access to the same RAM - no need to start transferring data through ssh.\n",
    "\n",
    "If you use two or more nodes, then at that point you are performing **distributed memory** parallelism and you will have to transfer data between nodes (again, most likely through an ssh connection). This opens up a whole world of possibilities, and this is what those cool fluid mechanics guys do to parallelise their stupidly large computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple parallelism with Julia\n",
    "\n",
    "You came here for one thing - to speed up your computations in Julia. So let's get too it!\n",
    "\n",
    "First things first, assuming you are solving an optimisation problem with a solver then you can speed this up by specifying the number of threads to be used to be equal to the maximum number on your laptop. For me this is 8 - 4 cores and 2 threads per core. You can easily google ways to figure out how many threads you have (this is obviously dependent on whether you're using Windows, Mac or Linux).\n",
    "\n",
    "The following example is 100% stolen from the [JuMP tutorials]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Cbc\n",
    "\n",
    "# Define some input data about the test system\n",
    "# Maximum power output of generators\n",
    "g_max = [1000, 1000];\n",
    "# Minimum power output of generators\n",
    "g_min = [0, 300];\n",
    "# Incremental cost of generators \n",
    "c_g = [50, 100];\n",
    "# Fixed cost of generators\n",
    "c_g0 = [1000, 0]\n",
    "# Incremental cost of wind generators\n",
    "c_w = 50;\n",
    "# Total demand\n",
    "d = 1500;\n",
    "# Wind forecast\n",
    "w_f = 200;\n",
    "\n",
    "# In this cell we introduce binary decision u to the economic dispatch problem (function solve_ed)\n",
    "function solve_uc(g_max, g_min, c_g, c_w, d, w_f, optimizer)\n",
    "    #Define the unit commitment (UC) model\n",
    "    uc = Model(optimizer)\n",
    "    \n",
    "    # Define decision variables    \n",
    "    @variable(uc, 0 <= g[i=1:2] <= g_max[i]) # power output of generators\n",
    "    @variable(uc, u[i = 1:2], Bin) # Binary status of generators\n",
    "    @variable(uc, 0 <= w <= w_f ) # wind power injection\n",
    "\n",
    "    # Define the objective function\n",
    "    @objective(uc, Min, dot(c_g, g) + c_w * w)\n",
    "\n",
    "    # Define the constraint on the maximum and minimum power output of each generator\n",
    "    @constraint(uc, [i = 1:2], g[i] <= g_max[i]) #maximum\n",
    "    @constraint(uc, [i = 1:2], g[i] >= g_min[i]) #minimum\n",
    "\n",
    "    # Define the constraint on the wind power injection\n",
    "    @constraint(uc, w <= w_f)\n",
    "\n",
    "    # Define the power balance constraint\n",
    "        @constraint(uc, sum(g) + w == d)\n",
    "\n",
    "    # Solve statement\n",
    "    optimize!(uc)\n",
    "    \n",
    "    status = termination_status(uc)\n",
    "    if status != MOI.OPTIMAL\n",
    "        return status, zeros(length(g)), 0.0, 0.0, zeros(length(u)), Inf\n",
    "    end\n",
    "    return status, value.(g), value(w), w_f - value(w), value.(u), objective_value(uc)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "println(\"Solution time with 1 thread:\")\n",
    "optimizer = optimizer_with_attributes(Cbc.Optimizer, \"threads\", 1)\n",
    "@btime status, g_opt, w_opt, ws_opt, u_opt, obj = solve_uc(g_max, g_min, c_g, c_w, d, w_f, optimizer);\n",
    "\n",
    "println(\"Solution time with 8 threads:\")\n",
    "optimizer = optimizer_with_attributes(Cbc.Optimizer, \"threads\", 8)\n",
    "@btime status, g_opt, w_opt, ws_opt, u_opt, obj = solve_uc(g_max, g_min, c_g, c_w, d, w_f, optimizer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding layers of parallelism with Julia\n",
    "\n",
    "I know I said forget about multi-threading, and you can live your life without knowing, but if you're curious then read on.\n",
    "\n",
    "To re-iterate, I don't recommend trying to write multithreaded programs because you'll mess it up and anyway someone has already done it for you in all likelihood. For example, most linear algebra operations within Julia are done using [BLAS]() which is already multithreaded. You can find out the number of threads BLAS is using by typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccall((:openblas_get_num_threads64_, Base.libblas_name), Cint, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These number of threads are independent of the number of threads you start Julia with (which you can do \n",
    "\n",
    "There are also packages, such as `Folds.jl`, which can help you write simple multithreaded programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Number of threads in use is $(Threads.nthreads(). You need more than one to see efficiency gains.\")\n",
    "using Folds\n",
    "A = rand(10000,10000)\n",
    "@btime sum(A); # not multithreaded\n",
    "@btime Folds.sum(A); # multithreaded"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
